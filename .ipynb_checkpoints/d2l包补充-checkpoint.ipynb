{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf4de88b-a218-4508-b313-b4886e458029",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Accumulator', 'AddNorm', 'AdditiveAttention', 'Animator', 'AttentionDecoder', 'BERTEncoder', 'BERTModel', 'BananasDataset', 'BasicScheduler', 'Benchmark', 'Classifier', 'DATA_HUB', 'DATA_URL', 'DataModule', 'Decoder', 'DotProductAttention', 'Encoder', 'EncoderDecoder', 'F', 'FashionMNIST', 'GRU', 'HPOScheduler', 'HPOSearcher', 'HPOTrainer', 'HPOTuner', 'HyperParameters', 'Image', 'LeNet', 'LinearRegression', 'LinearRegressionScratch', 'MTFraEng', 'MaskLM', 'MaskedSoftmaxCELoss', 'Module', 'MultiHeadAttention', 'NextSentencePred', 'PositionWiseFFN', 'PositionalEncoding', 'ProgressBoard', 'RNN', 'RNNLM', 'RNNLMScratch', 'RNNScratch', 'RandomGenerator', 'RandomSearcher', 'ResNeXtBlock', 'Residual', 'SGD', 'SNLIDataset', 'Seq2Seq', 'Seq2SeqEncoder', 'SoftmaxRegression', 'SuccessiveHalvingScheduler', 'SyntheticRegressionData', 'TimeMachine', 'Timer', 'TokenEmbedding', 'Trainer', 'TransformerEncoder', 'TransformerEncoderBlock', 'VOCSegDataset', 'VOC_CLASSES', 'VOC_COLORMAP', 'Vocab', '_WikiTextDataset', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', '_get_batch_loss_bert', '_get_mlm_data_from_tokens', '_get_next_sentence', '_get_nsp_data_from_paragraph', '_pad_bert_inputs', '_read_wiki', '_replace_mlm_tokens', 'abs', 'accuracy', 'add_to_class', 'annotate', 'arange', 'argmax', 'assign_anchor_to_bbox', 'astype', 'backend_inline', 'batch_matmul', 'batchify', 'bbox_to_rect', 'bleu', 'box_center_to_corner', 'box_corner_to_center', 'box_iou', 'build_array_nmt', 'check_len', 'check_shape', 'collections', 'concat', 'copyfile', 'corr2d', 'cos', 'cosh', 'cpu', 'd2l', 'data', 'defaultdict', 'display', 'distance_matrix', 'download', 'download_extract', 'evaluate_accuracy_gpu', 'evaluate_loss', 'exp', 'expand_dims', 'extract', 'eye', 'float32', 'frozen_lake', 'get_centers_and_contexts', 'get_data_ch11', 'get_dataloader_workers', 'get_fashion_mnist_labels', 'get_negatives', 'get_tokens_and_segments', 'gpu', 'grad_clipping', 'hashlib', 'hpo_objective_lenet', 'init_cnn', 'init_seq2seq', 'inspect', 'int32', 'int64', 'linreg', 'linspace', 'load_array', 'load_data_bananas', 'load_data_fashion_mnist', 'load_data_imdb', 'load_data_nmt', 'load_data_ptb', 'load_data_snli', 'load_data_voc', 'load_data_wiki', 'log', 'make_env', 'masked_softmax', 'math', 'matmul', 'meshgrid', 'multibox_detection', 'multibox_prior', 'multibox_target', 'nms', 'nn', 'nn_Module', 'normal', 'np', 'num_gpus', 'numpy', 'offset_boxes', 'offset_inverse', 'ones', 'ones_like', 'os', 'pd', 'plot', 'plt', 'predict_sentiment', 'predict_seq2seq', 'predict_snli', 'preprocess_nmt', 'rand', 'randn', 'random', 'rbfkernel', 're', 'read_csv_labels', 'read_data_bananas', 'read_data_nmt', 'read_imdb', 'read_ptb', 'read_snli', 'read_voc_images', 'reduce_mean', 'reduce_sum', 'reorg_test', 'reorg_train_valid', 'repeat', 'requests', 'reshape', 'resnet18', 'sequence_mask', 'set_axes', 'set_figsize', 'sgd', 'show_Q_function_progress', 'show_bboxes', 'show_heatmaps', 'show_images', 'show_list_len_pair_hist', 'show_trace_2d', 'show_value_function_progress', 'shutil', 'sigmoid', 'sin', 'sinh', 'size', 'split_batch', 'squared_loss', 'stack', 'subsample', 'swapaxes', 'synthetic_data', 'sys', 'tanh', 'tarfile', 'tensor', 'time', 'to', 'tokenize', 'tokenize_nmt', 'torch', 'torchvision', 'train_2d', 'train_batch_ch13', 'train_ch11', 'train_ch13', 'train_ch6', 'train_concise_ch11', 'train_seq2seq', 'transforms', 'transpose', 'truncate_pad', 'try_all_gpus', 'try_gpu', 'update_D', 'update_G', 'use_svg_display', 'voc_colormap2label', 'voc_label_indices', 'voc_rand_crop', 'zeros', 'zeros_like', 'zipfile']\n"
     ]
    }
   ],
   "source": [
    "import d2l.torch as d2l\n",
    "print(dir(d2l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90d9cdd-b3a6-475f-9296-9f5d64847e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ch3的实现\n",
    "def accuracy(y_hat, y):\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        y_hat = y_hat.argmax(dim=1)\n",
    "    cmp = y_hat.type(y.dtype) == y\n",
    "    return float(cmp.type(y.dtype).sum())\n",
    "\n",
    "def train_epoch_ch3(net, train_iter, loss, updater):\n",
    "    if isinstance(net, nn.Module):\n",
    "        net.train()\n",
    "    metric = d2l.Accumulator(3)  # [损失总和, 正确预测数, 样本数]\n",
    "    for X, y in train_iter:\n",
    "        # (a) 前向传播: 每个样本的 loss\n",
    "        l_values = loss(net(X), y)  # shape: [batch_size]\n",
    "        # (b) 取平均做反向传播\n",
    "        l_mean = l_values.mean()\n",
    "        if isinstance(updater, torch.optim.Optimizer):\n",
    "            updater.zero_grad()\n",
    "            l_mean.backward()\n",
    "            updater.step()\n",
    "        else:\n",
    "            l_mean.backward()\n",
    "            updater(X.shape[0])\n",
    "        # (c) 记录: 批量的总损失 + 正确数 + 样本数\n",
    "        metric.add(float(l_values.sum()), accuracy(net(X), y), y.numel())\n",
    "    # 返回整个 epoch 的平均损失和平均准确率\n",
    "    return metric[0] / metric[2], metric[1] / metric[2]\n",
    "\n",
    "def train_ch3(net, train_iter, test_iter, loss, num_epochs, updater):\n",
    "    animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs],\n",
    "                            legend=['train loss', 'train acc', 'test acc'])\n",
    "    for epoch in range(num_epochs):\n",
    "        train_metrics = train_epoch_ch3(net, train_iter, loss, updater)\n",
    "        test_acc = evaluate_accuracy(net, test_iter)\n",
    "        animator.add(epoch + 1, train_metrics + (test_acc,))\n",
    "    train_loss, train_acc = train_metrics\n",
    "    print(f'loss {train_loss:.3f}, train acc {train_acc:.3f}, '\n",
    "          f'test acc {test_acc:.3f}')\n",
    "\n",
    "def evaluate_accuracy(net, data_iter):\n",
    "    if isinstance(net, nn.Module):\n",
    "        net.eval()\n",
    "    metric = d2l.Accumulator(2)  # [正确预测数, 总数]\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            metric.add(accuracy(net(X), y), y.numel())\n",
    "    return metric[0] / metric[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21c4a72-c0d8-4548-aa52-082a052f866d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_ch3的实现\n",
    "def predict_ch3(net, test_iter, n=6):  # @save\n",
    "    \"\"\"预测标签并可视化结果\"\"\"\n",
    "    for X, y in test_iter:\n",
    "        break  # 只取第一个 batch\n",
    "    trues = d2l.get_fashion_mnist_labels(y)\n",
    "    preds = d2l.get_fashion_mnist_labels(net(X).argmax(axis=1))\n",
    "    d2l.show_images(X[0:n].squeeze(1), 1, n, titles=[true + '\\n' + pred for true, pred in zip(trues, preds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bacc183-cf74-4aa5-8b7d-35ca25294970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_time_machine的实现\n",
    "\n",
    "import re\n",
    "\n",
    "d2l.DATA_HUB['time_machine'] = (d2l.DATA_URL + 'timemachine.txt', '090b5e7e70c295757f55df93cb0a180b9691891a')\n",
    "def read_time_machine():\n",
    "    \"\"\"将时间机器数据集加载到文本行列表中\"\"\"\n",
    "    with open(d2l.download('time_machine'),'r') as f:\n",
    "        lines = f.readlines()\n",
    "    return [re.sub('[^A-Za-z]+',' ', line).strip().lower() for line in lines]\n",
    "\n",
    "lines = read_time_machine()\n",
    "print(f'# 文本总行数：{len(lines)}')\n",
    "print(lines[0])\n",
    "print(lines[10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
