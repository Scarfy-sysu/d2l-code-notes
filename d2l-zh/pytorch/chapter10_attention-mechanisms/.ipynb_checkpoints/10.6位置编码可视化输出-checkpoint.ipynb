{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88a41ce1-c4c5-42d6-8be1-da979afb0c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入 X:\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "\n",
      "位置编码 P:\n",
      "tensor([[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
      "          1.0000e+00,  0.0000e+00,  1.0000e+00],\n",
      "        [ 8.4147e-01,  5.4030e-01,  9.9833e-02,  9.9500e-01,  9.9998e-03,\n",
      "          9.9995e-01,  1.0000e-03,  1.0000e+00],\n",
      "        [ 9.0930e-01, -4.1615e-01,  1.9867e-01,  9.8007e-01,  1.9999e-02,\n",
      "          9.9980e-01,  2.0000e-03,  1.0000e+00],\n",
      "        [ 1.4112e-01, -9.8999e-01,  2.9552e-01,  9.5534e-01,  2.9995e-02,\n",
      "          9.9955e-01,  3.0000e-03,  1.0000e+00]])\n",
      "\n",
      "相加后的结果 X + P:\n",
      "tensor([[1.0000, 2.0000, 1.0000, 2.0000, 1.0000, 2.0000, 1.0000, 2.0000],\n",
      "        [1.8415, 1.5403, 1.0998, 1.9950, 1.0100, 1.9999, 1.0010, 2.0000],\n",
      "        [1.9093, 0.5839, 1.1987, 1.9801, 1.0200, 1.9998, 1.0020, 2.0000],\n",
      "        [1.1411, 0.0100, 1.2955, 1.9553, 1.0300, 1.9996, 1.0030, 2.0000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# 位置编码模块\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, num_hiddens, dropout, max_len=1000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.P = torch.zeros((1, max_len, num_hiddens))\n",
    "        X = torch.arange(max_len, dtype=torch.float32).reshape(-1, 1) / \\\n",
    "            torch.pow(10000, torch.arange(0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)\n",
    "        self.P[:, :, 0::2] = torch.sin(X)  # 偶数维\n",
    "        self.P[:, :, 1::2] = torch.cos(X)  # 奇数维\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X + self.P[:, :X.shape[1], :].to(X.device)\n",
    "        return self.dropout(X)\n",
    "\n",
    "# 初始化：维度为8，序列长度为4，dropout设为0以便观察\n",
    "encoding_dim, num_steps = 8, 4\n",
    "pos_encoding = PositionalEncoding(encoding_dim, dropout=0)\n",
    "pos_encoding.eval()\n",
    "\n",
    "# 构造一个值全为1的输入序列 X，形状为 (1, 4, 8)\n",
    "X = torch.ones((1, num_steps, encoding_dim))\n",
    "\n",
    "# 取前4个位置的编码向量\n",
    "P = pos_encoding.P[:, :num_steps, :]\n",
    "\n",
    "# 打印输入\n",
    "print(\"输入 X:\")\n",
    "print(X[0])\n",
    "\n",
    "# 打印位置编码\n",
    "print(\"\\n位置编码 P:\")\n",
    "print(P[0])\n",
    "\n",
    "# 打印相加后的结果\n",
    "print(\"\\n相加后的结果 X + P:\")\n",
    "print((X + P)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765828a3-b188-4b91-b851-ce24a78ff075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# col3 [2.0000, 1.9950, 1.9801, 1.9553]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
